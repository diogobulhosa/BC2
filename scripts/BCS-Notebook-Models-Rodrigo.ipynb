{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,f1_score, precision_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "#smote \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv(r'../data/Train_year.csv', index_col=0)\n",
    "y_Train = pd.read_csv(r'../data/y_Train_year.csv', index_col= 0)\n",
    "\n",
    "Test = pd.read_csv(r'../data/Test_year.csv', index_col= 0)\n",
    "y_Test = pd.read_csv(r'../data/y_Test_year.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ADR', 'LeadTime','StaysInWeekNights', 'TotalOfSpecialRequests',\n",
    "        'BookingChanges', 'PreviousBookingsNotCanceled', 'RequiredCarParkingSpaces', 'PreviousCancellations',\n",
    "        'x0_BB', 'x0_SC', 'x1_A', 'x1_B', 'x1_D',\n",
    "       'x1_E', 'x1_F', 'x1_G', 'x2_avg_booker', 'x2_good_booker',\n",
    "       'x2_low_booker', 'x2_no_booker', 'x2_super_booker', 'x3_Autumn',\n",
    "       'x3_Spring', 'x3_Summer', 'x4_Low_Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train/val and test dataframes \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(df_to_models[features], \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=15, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Test Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(X_train, X_val, y_train, pred_train , y_val, pred_val, model):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "    print(\"Score: \"+ str(model.score(X_train, y_train)))\n",
    "    print(\"F1 Score: \"+ str(f1_score(y_train, pred_train)))\n",
    "    print(\"Precision: \"+ str(precision_score(y_train, pred_train)))\n",
    "    \n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))\n",
    "    print(\"Score: \"+ str(model.score(X_val, y_val)))\n",
    "    print(\"F1 Score: \"+ str(f1_score(y_val, pred_val)))\n",
    "    print(\"Precision: \"+ str(precision_score(y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(model, data_to_slice, y_to_slice, columns_to_use, smote = True):\n",
    "    # apply kfold\n",
    "    skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "    # create lists to store the results from the different models \n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    f1_list = []\n",
    "    precision_list =[]\n",
    "    tn_avg = 0\n",
    "    fp_avg = 0\n",
    "    fn_avg = 0\n",
    "    tp_avg = 0\n",
    "    count = 0\n",
    "    for train_index, test_index in skf.split(data_to_slice[columns_to_use],y_to_slice):\n",
    "        # get the indexes of the observations assigned for each partition\n",
    "        X_train, X_val = data_to_slice[columns_to_use].iloc[train_index], data_to_slice[columns_to_use].iloc[test_index]\n",
    "        y_train, y_val = y_to_slice.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # SMOTE Ã‰ AQUI \n",
    "        if smote:\n",
    "             \n",
    "            smote = SMOTE(random_state = 11)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # applies the model \n",
    "        model_fit = model.fit(X_train, y_train)\n",
    "        # predicts training \n",
    "        y_pred_train =  model_fit.predict(X_train)\n",
    "        #predicts validation \n",
    "        y_pred_val = model_fit.predict(X_val)\n",
    "        # prints metric results \n",
    "        \n",
    "        #metrics(X_train, X_val, y_train, y_pred_train, y_val, y_pred_val, model)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "        count += 1\n",
    "        tn_avg += tn\n",
    "        fp_avg += fp\n",
    "        fn_avg += fn\n",
    "        tp_avg += tp\n",
    "\n",
    "        \n",
    "        value_train = model.score(X_train, y_train)\n",
    "        # check the mean accuracy for the test\n",
    "        value_test = model.score(X_val,y_val)\n",
    "        f1_score_val = f1_score(y_val, y_pred_val)\n",
    "        precision_val = precision_score(y_val, y_pred_val)\n",
    "        # append the accuracies, the time and the number of iterations in the corresponding list\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "        f1_list.append(f1_score_val)\n",
    "        precision_list.append(precision_val)\n",
    "  \n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_test = round(np.mean(score_test),3)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_test = round(np.std(score_test),2)\n",
    "    avg_f1 = round(np.mean(f1_list),3)\n",
    "    std_f1 = round(np.std(f1_list),2)\n",
    "    avg_precision = round(np.mean(precision_list),3)\n",
    "    std_precision = round(np.std(precision_list),2)\n",
    "\n",
    "    tn_avg = tn_avg / count\n",
    "    fp_avg = fp_avg / count\n",
    "    fn_avg = fn_avg / count\n",
    "    tp_avg = tp_avg / count\n",
    "    #print(confusion_matrix(y_val, y_pred_val))\n",
    "    print(str(tp_avg)+ ' , ' + str(tn_avg) + '\\n' + str(fp_avg) + ' , ' +  str(fn_avg))\n",
    "    return str(avg_train) + '+/-' + str(std_train),\\\n",
    "            str(avg_test) + '+/-' + str(std_test) , str(avg_f1) + '+/-' + str(std_f1), avg_f1,\\\n",
    "                ' Precision: ' + str(avg_precision) + '+/-' + str(std_precision), avg_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1555.92 , 2398.44\n",
      "1025.56 , 1640.48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.717+/-0.0',\n",
       " '0.597+/-0.01',\n",
       " '0.539+/-0.01',\n",
       " 0.539,\n",
       " ' Precision: 0.603+/-0.0',\n",
       " 0.603)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression(random_state=11)\n",
    "\n",
    "avg_score(LogReg, Train[features], y_Train,Train[features].columns, smote = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.05,\n",
       " 'dual': False,\n",
       " 'max_iter': 50,\n",
       " 'multi_class': 'multinomial',\n",
       " 'penalty': 'l1',\n",
       " 'solver': 'saga'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1','l2','elasticnet','none'],\n",
    "    'dual':[True, False],\n",
    "    'C':[0.05, 0.2, 0.5, 1, 2],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [50,100,200,500],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    \n",
    "}\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = LogReg, param_grid = param_grid, scoring = 'precision')\n",
    "\n",
    "grid_search.fit(X_train_val, y_train_val)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556.36 , 2403.44\n",
      "1020.56 , 1640.04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.717+/-0.0',\n",
       " '0.598+/-0.01',\n",
       " '0.539+/-0.0',\n",
       " 0.539,\n",
       " ' Precision: 0.604+/-0.01',\n",
       " 0.604)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression(random_state=11,C= 0.05,dual= False,max_iter= 50,\n",
    " multi_class= 'multinomial',penalty= 'l1', solver= 'saga' )\n",
    "\n",
    "avg_score(LogReg, Train[features], y_Train,Train[features].columns, smote = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242.12 , 3239.32\n",
      "2059.88 , 1956.28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.855+/-0.0',\n",
       " '0.527+/-0.01',\n",
       " '0.382+/-0.01',\n",
       " 0.382,\n",
       " ' Precision: 0.376+/-0.01',\n",
       " 0.376)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelKNN = KNeighborsClassifier()\n",
    "\n",
    "avg_score(modelKNN, X_train_val, y_train_val,X_train_val.columns, smote = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 50, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [5,10,50,100],\n",
    "    'weights':['uniform', 'distance'],\n",
    "    'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [10,30,50]\n",
    "}\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = modelKNN, param_grid = param_grid, scoring = 'precision')\n",
    "\n",
    "grid_search.fit(X_train_val, y_train_val)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280.88 , 3187.56\n",
      "2111.64 , 1917.52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.747+/-0.0',\n",
       " '0.526+/-0.0',\n",
       " '0.389+/-0.01',\n",
       " 0.389,\n",
       " ' Precision: 0.378+/-0.01',\n",
       " 0.378)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelKNN = KNeighborsClassifier(n_neighbors=50, weights='uniform',algorithm='auto',\n",
    "leaf_size= 10)\n",
    "\n",
    "avg_score(modelKNN, X_train_val, y_train_val,X_train_val.columns, smote = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ADR', 'Adults', 'ArrivalDateWeekNumber', 'BookingChanges', 'Children',\n",
       "       'DaysInWaitingList', 'LeadTime', 'PreviousBookingsNotCanceled',\n",
       "       'RequiredCarParkingSpaces', 'PreviousCancellations',\n",
       "       'PreviousCancellationRate', 'StaysInWeekendNights', 'StaysInWeekNights',\n",
       "       'TotalOfSpecialRequests', 'x0_BB', 'x0_SC', 'x1_A', 'x1_B', 'x1_D',\n",
       "       'x1_E', 'x1_F', 'x1_G', 'x2_avg_booker', 'x2_good_booker',\n",
       "       'x2_low_booker', 'x2_no_booker', 'x2_super_booker', 'x3_Autumn',\n",
       "       'x3_Spring', 'x3_Summer', 'x4_Low_Season'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_models.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c5bc60f1b709cc28d984b044e46a36e86d71fb0a6f2e3589923fa1d0135e80a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "#smote \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_models = pd.read_csv(r'../data/to_models.csv', index_col=0)\n",
    "y = pd.read_csv(r'../data/y.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train/val and test dataframes \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(df_to_models, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=15, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Test Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(X_train, X_val, y_train, pred_train , y_val, pred_val, model):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "    print(\"Score: \"+ str(model.score(X_train, y_train)))\n",
    "    print(\"F1 Score: \"+ str(f1_score(y_train, pred_train)))\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))\n",
    "    print(\"Score: \"+ str(model.score(X_val, y_val)))\n",
    "    print(\"F1 Score: \"+ str(f1_score(y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(model, data_to_slice, y_to_slice, columns_to_use, smote = True):\n",
    "    # apply kfold\n",
    "    skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "    # create lists to store the results from the different models \n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    f1_list = []\n",
    "    tn_avg = 0\n",
    "    fp_avg = 0\n",
    "    fn_avg = 0\n",
    "    tp_avg = 0\n",
    "    count = 0\n",
    "\n",
    "    for train_index, test_index in skf.split(data_to_slice[columns_to_use],y_to_slice):\n",
    "        # get the indexes of the observations assigned for each partition\n",
    "        X_train, X_val = data_to_slice[columns_to_use].iloc[train_index], data_to_slice[columns_to_use].iloc[test_index]\n",
    "        y_train, y_val = y_to_slice.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # SMOTE Ã‰ AQUI \n",
    "        if smote: \n",
    "            smote = SMOTE(random_state = 11)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "        # applies the model \n",
    "        model_fit = model.fit(X_train, y_train)\n",
    "        # predicts training \n",
    "        y_pred_train =  model_fit.predict(X_train)\n",
    "        #predicts validation \n",
    "        y_pred_val = model_fit.predict(X_val)\n",
    "        # prints metric results \n",
    "        \n",
    "        #metrics(X_train, X_val, y_train, y_pred_train, y_val, y_pred_val, model)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "        count += 1\n",
    "        tn_avg += tn\n",
    "        fp_avg += fp\n",
    "        fn_avg += fn\n",
    "        tp_avg += tp\n",
    "\n",
    "        \n",
    "        value_train = model.score(X_train, y_train)\n",
    "        # check the mean accuracy for the test\n",
    "        value_test = model.score(X_val,y_val)\n",
    "        f1_score_val = f1_score(y_val, y_pred_val)\n",
    "        # append the accuracies, the time and the number of iterations in the corresponding list\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "        f1_list.append(f1_score_val)\n",
    "  \n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_test = round(np.mean(score_test),3)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_test = round(np.std(score_test),2)\n",
    "    avg_f1 = round(np.mean(f1_list),3)\n",
    "    std_f1 = round(np.std(f1_list),2)\n",
    "\n",
    "    tn_avg = tn_avg / count\n",
    "    fp_avg = fp_avg / count\n",
    "    fn_avg = fn_avg / count\n",
    "    tp_avg = tp_avg / count\n",
    "    #print(confusion_matrix(y_val, y_pred_val))\n",
    "    confmatrix = str(tp_avg)+ ' , ' + str(tn_avg) + '\\\\n' + str(fp_avg) + ' , ' +  str(fn_avg)\n",
    "    return str(avg_train) + '+/-' + str(std_train),\\\n",
    "            str(avg_test) + '+/-' + str(std_test) , str(avg_f1) + '+/-' + str(std_f1), avg_f1, confmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.731+/-0.0',\n",
       " '0.524+/-0.0',\n",
       " '0.393+/-0.01',\n",
       " 0.393,\n",
       " '1311.2 , 3142.12\\\\n2157.08 , 1887.2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression()\n",
    "\n",
    "avg_score(LogReg, X_train_val, y_train_val,X_train_val.columns, smote = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c5bc60f1b709cc28d984b044e46a36e86d71fb0a6f2e3589923fa1d0135e80a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import precision_score, classification_report, confusion_matrix,f1_score, recall_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "#smote \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv(r'../data/Train_year.csv', index_col=0)\n",
    "y_Train = pd.read_csv(r'../data/y_Train_year.csv', index_col= 0)\n",
    "\n",
    "Test = pd.read_csv(r'../data/Test_year.csv', index_col= 0)\n",
    "y_Test = pd.read_csv(r'../data/y_Test_year.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ADR', 'LeadTime','StaysInWeekNights', 'TotalOfSpecialRequests',\n",
    "        'BookingChanges', 'PreviousBookingsNotCanceled', 'RequiredCarParkingSpaces', 'PreviousCancellations',\n",
    "        'x0_BB', 'x0_SC', 'x1_A', 'x1_B', 'x1_D',\n",
    "       'x1_E', 'x1_F', 'x1_G', 'x2_avg_booker', 'x2_good_booker',\n",
    "       'x2_low_booker', 'x2_no_booker', 'x2_super_booker', 'x3_Autumn',\n",
    "       'x3_Spring', 'x3_Summer', 'x4_Low_Season']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Test Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(X_train, X_val, y_train, pred_train , y_val, pred_val, model):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "    print(\"Score: \"+ str(model.score(X_train, y_train)))\n",
    "    print(\"F1 Score: \"+ str(f1_score(y_train, pred_train)))\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))\n",
    "    print(\"Score: \"+ str(model.score(X_val, y_val)))\n",
    "    print(\"F1 Score: \"+ str(f1_score(y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(model, data_to_slice, y_to_slice, columns_to_use, smote = True):\n",
    "    # apply kfold\n",
    "    skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "    # create lists to store the results from the different models \n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    f1_list = []\n",
    "    precision_list =[]\n",
    "    recall_list = []\n",
    "    tn_avg = 0\n",
    "    fp_avg = 0\n",
    "    fn_avg = 0\n",
    "    tp_avg = 0\n",
    "    count = 0\n",
    "    for train_index, test_index in skf.split(data_to_slice[columns_to_use],y_to_slice):\n",
    "        # get the indexes of the observations assigned for each partition\n",
    "        X_train, X_val = data_to_slice[columns_to_use].iloc[train_index], data_to_slice[columns_to_use].iloc[test_index]\n",
    "        y_train, y_val = y_to_slice.iloc[train_index], y_to_slice.iloc[test_index]\n",
    "        \n",
    "        # SMOTE Ã‰ AQUI \n",
    "        if smote:\n",
    "             \n",
    "            smote = SMOTE(random_state = 11)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # applies the model \n",
    "        model_fit = model.fit(X_train, y_train)\n",
    "        # predicts training \n",
    "        y_pred_train =  model_fit.predict(X_train)\n",
    "        #predicts validation \n",
    "        y_pred_val = model_fit.predict(X_val)\n",
    "        # prints metric results \n",
    "        \n",
    "        #metrics(X_train, X_val, y_train, y_pred_train, y_val, y_pred_val, model)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "        count += 1\n",
    "        tn_avg += tn\n",
    "        fp_avg += fp\n",
    "        fn_avg += fn\n",
    "        tp_avg += tp\n",
    "\n",
    "        \n",
    "        value_train = model.score(X_train, y_train)\n",
    "        # check the mean accuracy for the test\n",
    "        value_test = model.score(X_val,y_val)\n",
    "        f1_score_val = f1_score(y_val, y_pred_val)\n",
    "        precision_val = precision_score(y_val, y_pred_val)\n",
    "        recall_val = recall_score(y_val, y_pred_val)\n",
    "        # append the accuracies, the time and the number of iterations in the corresponding list\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "        f1_list.append(f1_score_val)\n",
    "        precision_list.append(precision_val)\n",
    "        recall_list.append(recall_val)\n",
    "  \n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_test = round(np.mean(score_test),3)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_test = round(np.std(score_test),2)\n",
    "    avg_f1 = round(np.mean(f1_list),3)\n",
    "    std_f1 = round(np.std(f1_list),2)\n",
    "    avg_precision = round(np.mean(precision_list),3)\n",
    "    std_precision = round(np.std(precision_list),2)\n",
    "    avg_recall = round(np.mean(recall_list), 3)\n",
    "    std_recall = round(np.mean(recall_list),2)\n",
    "\n",
    "    tn_avg = tn_avg / count\n",
    "    fp_avg = fp_avg / count\n",
    "    fn_avg = fn_avg / count\n",
    "    tp_avg = tp_avg / count\n",
    "    #print(confusion_matrix(y_val, y_pred_val))\n",
    "    print(str(tp_avg)+ ' , ' + str(fp_avg) + '\\n' + str(fn_avg) + ' , ' +  str(tn_avg))\n",
    "    return str(avg_train) + '+/-' + str(std_train),\\\n",
    "            str(avg_test) + '+/-' + str(std_test) ,\\\n",
    "            'F1 SCORE : ' + str(avg_f1) + '+/-' + str(std_f1), \\\n",
    "            'Precision : ' + str(avg_precision) + '+/-' + str(std_precision), \\\n",
    "            'RECALL :'+ str(avg_recall)+ '+/-' + str(std_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "n_estimators = np.arange(1, 50)\n",
    "train_results = []\n",
    "test_results = []\n",
    "diff=[]\n",
    "\n",
    "for estimator in n_estimators:\n",
    "    rf = RandomForestClassifier(n_estimators=estimator, criterion= 'gini')\n",
    "    rf.fit(Train, y_Train)\n",
    "    train_pred = rf.predict(Train)\n",
    "    train_score = f1_score(y_Train,train_pred)\n",
    "    train_results.append(train_score)\n",
    "    \n",
    "    test_pred = rf.predict(Test)\n",
    "    val_score = f1_score(y_Test,test_pred)\n",
    "    test_results.append(val_score)\n",
    "    diff.append(val_score-train_score)\n",
    "    \n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label='Train F1')\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label='Test F1')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.980280</td>\n",
       "      <td>0.506841</td>\n",
       "      <td>-0.473439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.982950</td>\n",
       "      <td>0.506184</td>\n",
       "      <td>-0.476767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.982597</td>\n",
       "      <td>0.503778</td>\n",
       "      <td>-0.478819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.973629</td>\n",
       "      <td>0.502555</td>\n",
       "      <td>-0.471074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.979473</td>\n",
       "      <td>0.502036</td>\n",
       "      <td>-0.477437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.982769</td>\n",
       "      <td>0.501532</td>\n",
       "      <td>-0.481237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.977829</td>\n",
       "      <td>0.500131</td>\n",
       "      <td>-0.477698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.965552</td>\n",
       "      <td>0.500128</td>\n",
       "      <td>-0.465423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.982978</td>\n",
       "      <td>0.499514</td>\n",
       "      <td>-0.483464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.982474</td>\n",
       "      <td>0.498629</td>\n",
       "      <td>-0.483844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.953545</td>\n",
       "      <td>0.498434</td>\n",
       "      <td>-0.455111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.982234</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>-0.483811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.982786</td>\n",
       "      <td>0.498241</td>\n",
       "      <td>-0.484545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.981902</td>\n",
       "      <td>0.498076</td>\n",
       "      <td>-0.483826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.981490</td>\n",
       "      <td>0.497882</td>\n",
       "      <td>-0.483608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.497719</td>\n",
       "      <td>-0.482703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.983042</td>\n",
       "      <td>0.497709</td>\n",
       "      <td>-0.485333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.495884</td>\n",
       "      <td>-0.486393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.975039</td>\n",
       "      <td>0.495160</td>\n",
       "      <td>-0.479879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.981626</td>\n",
       "      <td>0.494891</td>\n",
       "      <td>-0.486735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.982902</td>\n",
       "      <td>0.494782</td>\n",
       "      <td>-0.488120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.982124</td>\n",
       "      <td>0.494307</td>\n",
       "      <td>-0.487818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.981118</td>\n",
       "      <td>0.494182</td>\n",
       "      <td>-0.486936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.979921</td>\n",
       "      <td>0.493880</td>\n",
       "      <td>-0.486041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.981178</td>\n",
       "      <td>0.493860</td>\n",
       "      <td>-0.487318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.982114</td>\n",
       "      <td>0.493059</td>\n",
       "      <td>-0.489056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.979019</td>\n",
       "      <td>0.492646</td>\n",
       "      <td>-0.486372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.981332</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>-0.489456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.973959</td>\n",
       "      <td>0.491133</td>\n",
       "      <td>-0.482827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.980569</td>\n",
       "      <td>0.490870</td>\n",
       "      <td>-0.489699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.977520</td>\n",
       "      <td>0.490263</td>\n",
       "      <td>-0.487257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.937085</td>\n",
       "      <td>0.489351</td>\n",
       "      <td>-0.447734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.970320</td>\n",
       "      <td>0.488950</td>\n",
       "      <td>-0.481370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.978700</td>\n",
       "      <td>0.488909</td>\n",
       "      <td>-0.489791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.977807</td>\n",
       "      <td>0.487118</td>\n",
       "      <td>-0.490689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.973607</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>-0.487207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.972871</td>\n",
       "      <td>0.482151</td>\n",
       "      <td>-0.490720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.959933</td>\n",
       "      <td>0.481246</td>\n",
       "      <td>-0.478688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.965544</td>\n",
       "      <td>0.479357</td>\n",
       "      <td>-0.486188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.969021</td>\n",
       "      <td>0.479075</td>\n",
       "      <td>-0.489945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.912226</td>\n",
       "      <td>0.477578</td>\n",
       "      <td>-0.434648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.976867</td>\n",
       "      <td>0.475176</td>\n",
       "      <td>-0.501691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.956449</td>\n",
       "      <td>0.472091</td>\n",
       "      <td>-0.484357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.961659</td>\n",
       "      <td>0.470098</td>\n",
       "      <td>-0.491561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.454001</td>\n",
       "      <td>-0.490770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829965</td>\n",
       "      <td>0.447862</td>\n",
       "      <td>-0.382103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.928857</td>\n",
       "      <td>0.443357</td>\n",
       "      <td>-0.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.899268</td>\n",
       "      <td>0.415162</td>\n",
       "      <td>-0.484105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.811413</td>\n",
       "      <td>0.353416</td>\n",
       "      <td>-0.457997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators     Train       Val      Diff\n",
       "26          27.0  0.980280  0.506841 -0.473439\n",
       "38          39.0  0.982950  0.506184 -0.476767\n",
       "46          47.0  0.982597  0.503778 -0.478819\n",
       "14          15.0  0.973629  0.502555 -0.471074\n",
       "22          23.0  0.979473  0.502036 -0.477437\n",
       "42          43.0  0.982769  0.501532 -0.481237\n",
       "20          21.0  0.977829  0.500131 -0.477698\n",
       "10          11.0  0.965552  0.500128 -0.465423\n",
       "47          48.0  0.982978  0.499514 -0.483464\n",
       "45          46.0  0.982474  0.498629 -0.483844\n",
       "6            7.0  0.953545  0.498434 -0.455111\n",
       "34          35.0  0.982234  0.498423 -0.483811\n",
       "48          49.0  0.982786  0.498241 -0.484545\n",
       "36          37.0  0.981902  0.498076 -0.483826\n",
       "37          38.0  0.981490  0.497882 -0.483608\n",
       "28          29.0  0.980422  0.497719 -0.482703\n",
       "40          41.0  0.983042  0.497709 -0.485333\n",
       "43          44.0  0.982277  0.495884 -0.486393\n",
       "18          19.0  0.975039  0.495160 -0.479879\n",
       "32          33.0  0.981626  0.494891 -0.486735\n",
       "44          45.0  0.982902  0.494782 -0.488120\n",
       "39          40.0  0.982124  0.494307 -0.487818\n",
       "30          31.0  0.981118  0.494182 -0.486936\n",
       "29          30.0  0.979921  0.493880 -0.486041\n",
       "35          36.0  0.981178  0.493860 -0.487318\n",
       "41          42.0  0.982114  0.493059 -0.489056\n",
       "24          25.0  0.979019  0.492646 -0.486372\n",
       "33          34.0  0.981332  0.491876 -0.489456\n",
       "16          17.0  0.973959  0.491133 -0.482827\n",
       "31          32.0  0.980569  0.490870 -0.489699\n",
       "25          26.0  0.977520  0.490263 -0.487257\n",
       "4            5.0  0.937085  0.489351 -0.447734\n",
       "12          13.0  0.970320  0.488950 -0.481370\n",
       "27          28.0  0.978700  0.488909 -0.489791\n",
       "23          24.0  0.977807  0.487118 -0.490689\n",
       "19          20.0  0.973607  0.486400 -0.487207\n",
       "17          18.0  0.972871  0.482151 -0.490720\n",
       "8            9.0  0.959933  0.481246 -0.478688\n",
       "13          14.0  0.965544  0.479357 -0.486188\n",
       "15          16.0  0.969021  0.479075 -0.489945\n",
       "2            3.0  0.912226  0.477578 -0.434648\n",
       "21          22.0  0.976867  0.475176 -0.501691\n",
       "9           10.0  0.956449  0.472091 -0.484357\n",
       "11          12.0  0.961659  0.470098 -0.491561\n",
       "7            8.0  0.944771  0.454001 -0.490770\n",
       "0            1.0  0.829965  0.447862 -0.382103\n",
       "5            6.0  0.928857  0.443357 -0.485500\n",
       "3            4.0  0.899268  0.415162 -0.484105\n",
       "1            2.0  0.811413  0.353416 -0.457997"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estimator=pd.DataFrame([pd.Series(n_estimators,name='n_estimators',dtype=int),pd.Series(train_results,name='Train'),pd.Series(test_results,name='Val'),pd.Series(diff,name='Diff')]).T\n",
    "df_estimator.sort_values(by='Val',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gini = RandomForestClassifier(criterion='gini', n_estimators=25)\n",
    "rf_entropy = RandomForestClassifier(criterion='entropy', n_estimators=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116.96 , 527.76\n",
      "718.24 , 4257.44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.993+/-0.0',\n",
       " '0.812+/-0.0',\n",
       " '0.642+/-0.01',\n",
       " 0.642,\n",
       " ' Precision: 0.679+/-0.01',\n",
       " 0.679,\n",
       " 'RECALL :0.609+/-0.61')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score(rf_gini, Train, y_Train, Train.columns,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112.96 , 4251.96\n",
      "533.24 , 722.24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.993+/-0.0',\n",
       " '0.81+/-0.0',\n",
       " '0.639+/-0.01',\n",
       " 0.639,\n",
       " ' Precision: 0.676+/-0.01',\n",
       " 0.676,\n",
       " 'RECALL :0.606+/-0.61')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score(rf_entropy, Train, y_Train, Train.columns,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf_entropy.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5594\n",
      "IsCanceled    6826\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(prediction.sum())\n",
    "\n",
    "print(y_Test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14161"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "for i,x in enumerate(y_Test.IsCanceled):\n",
    "    if prediction[i] == x:\n",
    "        a+=1\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy looks like the best choice although both criterias are very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 15,\n",
       "  'min_impurity_decrease': 0.00010110909090909092,\n",
       "  'min_samples_leaf': 120,\n",
       "  'min_samples_split': 50,\n",
       "  'n_estimators': 25},\n",
       " 0.12859546190376617)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # forest params\n",
    "# param_grid = { \n",
    "#     'max_depth' : range(12,20),\n",
    "#     'n_estimators' : range(25,27),\n",
    "#     'min_impurity_decrease' : np.linspace(0.0000001,0.01,100),\n",
    "#     'min_samples_leaf': range(110,140,10),\n",
    "#     'min_samples_split':range(50,100,10)\n",
    "# }\n",
    "\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf_entropy, param_grid = param_grid, scoring = 'f1')\n",
    "\n",
    "# grid_search.fit(Train, y_Train)\n",
    "# grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1299.88 , 698.08\n",
      "535.32 , 4087.12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.833+/-0.0',\n",
       " '0.814+/-0.0',\n",
       " 'F1 SCORE : 0.678+/-0.01',\n",
       " 'Precision : 0.651+/-0.01',\n",
       " 0.651,\n",
       " 'RECALL :0.708+/-0.71')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(criterion='entropy', max_depth=15, min_impurity_decrease=0.00010110909090909092, min_samples_leaf=120, min_samples_split=50, n_estimators=130)\n",
    "avg_score(rf_model, Train, y_Train, Train.columns,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315.2 , 651.52\n",
      "520.0 , 4133.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.86+/-0.0',\n",
       " '0.823+/-0.0',\n",
       " 'F1 SCORE : 0.692+/-0.01',\n",
       " 'Precision : 0.669+/-0.01',\n",
       " 'RECALL :0.717+/-0.72')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model2 = RandomForestClassifier(n_estimators=130, max_depth=15, min_impurity_decrease=0.00010110909090909092)\n",
    "avg_score(rf_model2, Train, y_Train, Train.columns, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred1 = rf_model.predict(Test)\n",
    "y_test_pred2 = rf_model2.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15009"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "for i,x in enumerate(y_Test.IsCanceled):\n",
    "    if y_test_pred1[i] == x:\n",
    "        a+=1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15089"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "for i,x in enumerate(y_Test.IsCanceled):\n",
    "    if y_test_pred2[i] == x:\n",
    "        a+=1\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c5bc60f1b709cc28d984b044e46a36e86d71fb0a6f2e3589923fa1d0135e80a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

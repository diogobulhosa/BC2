{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import precision_score, classification_report, confusion_matrix,f1_score, recall_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "#smote \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv(r'../data/Train_year.csv', index_col=0)\n",
    "y_Train = pd.read_csv(r'../data/y_Train_year.csv', index_col= 0)\n",
    "\n",
    "Test = pd.read_csv(r'../data/Test_year.csv', index_col= 0)\n",
    "y_Test = pd.read_csv(r'../data/y_Test_year.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ADR', 'LeadTime','StaysInWeekNights', 'TotalOfSpecialRequests',\n",
    "        'BookingChanges', 'PreviousBookingsNotCanceled', 'RequiredCarParkingSpaces', 'PreviousCancellations',\n",
    "        'x0_BB', 'x0_SC', 'x1_A', 'x1_B', 'x1_D',\n",
    "       'x1_E', 'x1_F', 'x1_G', 'x2_avg_booker', 'x2_good_booker',\n",
    "       'x2_low_booker', 'x2_no_booker', 'x2_super_booker', 'x3_Autumn',\n",
    "       'x3_Spring', 'x3_Summer', 'x4_Low_Season']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Test Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(X_train, X_val, y_train, pred_train , y_val, pred_val, model):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "    print(\"Score: \"+ str(model.score(X_train, y_train)))\n",
    "    print(\"F1 Score: \"+ str(f1_score(y_train, pred_train)))\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))\n",
    "    print(\"Score: \"+ str(model.score(X_val, y_val)))\n",
    "    print(\"F1 Score: \"+ str(f1_score(y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(model, data_to_slice, y_to_slice, columns_to_use, smote = True):\n",
    "    # apply kfold\n",
    "    skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "    # create lists to store the results from the different models \n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    f1_list = []\n",
    "    precision_list =[]\n",
    "    recall_list = []\n",
    "    tn_avg = 0\n",
    "    fp_avg = 0\n",
    "    fn_avg = 0\n",
    "    tp_avg = 0\n",
    "    count = 0\n",
    "    for train_index, test_index in skf.split(data_to_slice[columns_to_use],y_to_slice):\n",
    "        # get the indexes of the observations assigned for each partition\n",
    "        X_train, X_val = data_to_slice[columns_to_use].iloc[train_index], data_to_slice[columns_to_use].iloc[test_index]\n",
    "        y_train, y_val = y_to_slice.iloc[train_index], y_to_slice.iloc[test_index]\n",
    "        \n",
    "        # SMOTE Ã‰ AQUI \n",
    "        if smote:\n",
    "             \n",
    "            smote = SMOTE(random_state = 11)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # applies the model \n",
    "        model_fit = model.fit(X_train, y_train)\n",
    "        # predicts training \n",
    "        y_pred_train =  model_fit.predict(X_train)\n",
    "        #predicts validation \n",
    "        y_pred_val = model_fit.predict(X_val)\n",
    "        # prints metric results \n",
    "        \n",
    "        #metrics(X_train, X_val, y_train, y_pred_train, y_val, y_pred_val, model)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "        count += 1\n",
    "        tn_avg += tn\n",
    "        fp_avg += fp\n",
    "        fn_avg += fn\n",
    "        tp_avg += tp\n",
    "\n",
    "        \n",
    "        value_train = model.score(X_train, y_train)\n",
    "        # check the mean accuracy for the test\n",
    "        value_test = model.score(X_val,y_val)\n",
    "        f1_score_val = f1_score(y_val, y_pred_val)\n",
    "        precision_val = precision_score(y_val, y_pred_val)\n",
    "        recall_val = recall_score(y_val, y_pred_val)\n",
    "        # append the accuracies, the time and the number of iterations in the corresponding list\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "        f1_list.append(f1_score_val)\n",
    "        precision_list.append(precision_val)\n",
    "        recall_list.append(recall_val)\n",
    "  \n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_test = round(np.mean(score_test),3)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_test = round(np.std(score_test),2)\n",
    "    avg_f1 = round(np.mean(f1_list),3)\n",
    "    std_f1 = round(np.std(f1_list),2)\n",
    "    avg_precision = round(np.mean(precision_list),3)\n",
    "    std_precision = round(np.std(precision_list),2)\n",
    "    avg_recall = round(np.mean(recall_list), 3)\n",
    "    std_recall = round(np.mean(recall_list),2)\n",
    "\n",
    "    tn_avg = tn_avg / count\n",
    "    fp_avg = fp_avg / count\n",
    "    fn_avg = fn_avg / count\n",
    "    tp_avg = tp_avg / count\n",
    "    #print(confusion_matrix(y_val, y_pred_val))\n",
    "    print(str(tp_avg)+ ' , ' + str(fp_avg) + '\\n' + str(fn_avg) + ' , ' +  str(tn_avg))\n",
    "    return str(avg_train) + '+/-' + str(std_train),\\\n",
    "            str(avg_test) + '+/-' + str(std_test) , str(avg_f1) + '+/-' + str(std_f1), avg_f1,\\\n",
    "                ' Precision: ' + str(avg_precision) + '+/-' + str(std_precision), avg_precision, \\\n",
    "            'RECALL :'+ str(avg_recall)+ '+/-' + str(std_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "n_estimators = np.arange(1, 50)\n",
    "train_results = []\n",
    "test_results = []\n",
    "diff=[]\n",
    "\n",
    "for estimator in n_estimators:\n",
    "    rf = RandomForestClassifier(n_estimators=estimator, criterion= 'gini')\n",
    "    rf.fit(Train, y_Train)\n",
    "    train_pred = rf.predict(Train)\n",
    "    train_score = f1_score(y_Train,train_pred)\n",
    "    train_results.append(train_score)\n",
    "    \n",
    "    test_pred = rf.predict(Test)\n",
    "    val_score = f1_score(y_Test,test_pred)\n",
    "    test_results.append(val_score)\n",
    "    diff.append(val_score-train_score)\n",
    "    \n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label='Train F1')\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label='Test F1')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.980280</td>\n",
       "      <td>0.506841</td>\n",
       "      <td>-0.473439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.982950</td>\n",
       "      <td>0.506184</td>\n",
       "      <td>-0.476767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.982597</td>\n",
       "      <td>0.503778</td>\n",
       "      <td>-0.478819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.973629</td>\n",
       "      <td>0.502555</td>\n",
       "      <td>-0.471074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.979473</td>\n",
       "      <td>0.502036</td>\n",
       "      <td>-0.477437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.982769</td>\n",
       "      <td>0.501532</td>\n",
       "      <td>-0.481237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.977829</td>\n",
       "      <td>0.500131</td>\n",
       "      <td>-0.477698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.965552</td>\n",
       "      <td>0.500128</td>\n",
       "      <td>-0.465423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.982978</td>\n",
       "      <td>0.499514</td>\n",
       "      <td>-0.483464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.982474</td>\n",
       "      <td>0.498629</td>\n",
       "      <td>-0.483844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.953545</td>\n",
       "      <td>0.498434</td>\n",
       "      <td>-0.455111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.982234</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>-0.483811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.982786</td>\n",
       "      <td>0.498241</td>\n",
       "      <td>-0.484545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.981902</td>\n",
       "      <td>0.498076</td>\n",
       "      <td>-0.483826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.981490</td>\n",
       "      <td>0.497882</td>\n",
       "      <td>-0.483608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.497719</td>\n",
       "      <td>-0.482703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.983042</td>\n",
       "      <td>0.497709</td>\n",
       "      <td>-0.485333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.495884</td>\n",
       "      <td>-0.486393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.975039</td>\n",
       "      <td>0.495160</td>\n",
       "      <td>-0.479879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.981626</td>\n",
       "      <td>0.494891</td>\n",
       "      <td>-0.486735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.982902</td>\n",
       "      <td>0.494782</td>\n",
       "      <td>-0.488120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.982124</td>\n",
       "      <td>0.494307</td>\n",
       "      <td>-0.487818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.981118</td>\n",
       "      <td>0.494182</td>\n",
       "      <td>-0.486936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.979921</td>\n",
       "      <td>0.493880</td>\n",
       "      <td>-0.486041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.981178</td>\n",
       "      <td>0.493860</td>\n",
       "      <td>-0.487318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.982114</td>\n",
       "      <td>0.493059</td>\n",
       "      <td>-0.489056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.979019</td>\n",
       "      <td>0.492646</td>\n",
       "      <td>-0.486372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.981332</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>-0.489456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.973959</td>\n",
       "      <td>0.491133</td>\n",
       "      <td>-0.482827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.980569</td>\n",
       "      <td>0.490870</td>\n",
       "      <td>-0.489699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.977520</td>\n",
       "      <td>0.490263</td>\n",
       "      <td>-0.487257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.937085</td>\n",
       "      <td>0.489351</td>\n",
       "      <td>-0.447734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.970320</td>\n",
       "      <td>0.488950</td>\n",
       "      <td>-0.481370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.978700</td>\n",
       "      <td>0.488909</td>\n",
       "      <td>-0.489791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.977807</td>\n",
       "      <td>0.487118</td>\n",
       "      <td>-0.490689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.973607</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>-0.487207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.972871</td>\n",
       "      <td>0.482151</td>\n",
       "      <td>-0.490720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.959933</td>\n",
       "      <td>0.481246</td>\n",
       "      <td>-0.478688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.965544</td>\n",
       "      <td>0.479357</td>\n",
       "      <td>-0.486188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.969021</td>\n",
       "      <td>0.479075</td>\n",
       "      <td>-0.489945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.912226</td>\n",
       "      <td>0.477578</td>\n",
       "      <td>-0.434648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.976867</td>\n",
       "      <td>0.475176</td>\n",
       "      <td>-0.501691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.956449</td>\n",
       "      <td>0.472091</td>\n",
       "      <td>-0.484357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.961659</td>\n",
       "      <td>0.470098</td>\n",
       "      <td>-0.491561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.454001</td>\n",
       "      <td>-0.490770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829965</td>\n",
       "      <td>0.447862</td>\n",
       "      <td>-0.382103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.928857</td>\n",
       "      <td>0.443357</td>\n",
       "      <td>-0.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.899268</td>\n",
       "      <td>0.415162</td>\n",
       "      <td>-0.484105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.811413</td>\n",
       "      <td>0.353416</td>\n",
       "      <td>-0.457997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators     Train       Val      Diff\n",
       "26          27.0  0.980280  0.506841 -0.473439\n",
       "38          39.0  0.982950  0.506184 -0.476767\n",
       "46          47.0  0.982597  0.503778 -0.478819\n",
       "14          15.0  0.973629  0.502555 -0.471074\n",
       "22          23.0  0.979473  0.502036 -0.477437\n",
       "42          43.0  0.982769  0.501532 -0.481237\n",
       "20          21.0  0.977829  0.500131 -0.477698\n",
       "10          11.0  0.965552  0.500128 -0.465423\n",
       "47          48.0  0.982978  0.499514 -0.483464\n",
       "45          46.0  0.982474  0.498629 -0.483844\n",
       "6            7.0  0.953545  0.498434 -0.455111\n",
       "34          35.0  0.982234  0.498423 -0.483811\n",
       "48          49.0  0.982786  0.498241 -0.484545\n",
       "36          37.0  0.981902  0.498076 -0.483826\n",
       "37          38.0  0.981490  0.497882 -0.483608\n",
       "28          29.0  0.980422  0.497719 -0.482703\n",
       "40          41.0  0.983042  0.497709 -0.485333\n",
       "43          44.0  0.982277  0.495884 -0.486393\n",
       "18          19.0  0.975039  0.495160 -0.479879\n",
       "32          33.0  0.981626  0.494891 -0.486735\n",
       "44          45.0  0.982902  0.494782 -0.488120\n",
       "39          40.0  0.982124  0.494307 -0.487818\n",
       "30          31.0  0.981118  0.494182 -0.486936\n",
       "29          30.0  0.979921  0.493880 -0.486041\n",
       "35          36.0  0.981178  0.493860 -0.487318\n",
       "41          42.0  0.982114  0.493059 -0.489056\n",
       "24          25.0  0.979019  0.492646 -0.486372\n",
       "33          34.0  0.981332  0.491876 -0.489456\n",
       "16          17.0  0.973959  0.491133 -0.482827\n",
       "31          32.0  0.980569  0.490870 -0.489699\n",
       "25          26.0  0.977520  0.490263 -0.487257\n",
       "4            5.0  0.937085  0.489351 -0.447734\n",
       "12          13.0  0.970320  0.488950 -0.481370\n",
       "27          28.0  0.978700  0.488909 -0.489791\n",
       "23          24.0  0.977807  0.487118 -0.490689\n",
       "19          20.0  0.973607  0.486400 -0.487207\n",
       "17          18.0  0.972871  0.482151 -0.490720\n",
       "8            9.0  0.959933  0.481246 -0.478688\n",
       "13          14.0  0.965544  0.479357 -0.486188\n",
       "15          16.0  0.969021  0.479075 -0.489945\n",
       "2            3.0  0.912226  0.477578 -0.434648\n",
       "21          22.0  0.976867  0.475176 -0.501691\n",
       "9           10.0  0.956449  0.472091 -0.484357\n",
       "11          12.0  0.961659  0.470098 -0.491561\n",
       "7            8.0  0.944771  0.454001 -0.490770\n",
       "0            1.0  0.829965  0.447862 -0.382103\n",
       "5            6.0  0.928857  0.443357 -0.485500\n",
       "3            4.0  0.899268  0.415162 -0.484105\n",
       "1            2.0  0.811413  0.353416 -0.457997"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estimator=pd.DataFrame([pd.Series(n_estimators,name='n_estimators',dtype=int),pd.Series(train_results,name='Train'),pd.Series(test_results,name='Val'),pd.Series(diff,name='Diff')]).T\n",
    "df_estimator.sort_values(by='Val',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gini = RandomForestClassifier(criterion='gini', n_estimators=25)\n",
    "rf_entropy = RandomForestClassifier(criterion='entropy', n_estimators=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116.96 , 527.76\n",
      "718.24 , 4257.44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.993+/-0.0',\n",
       " '0.812+/-0.0',\n",
       " '0.642+/-0.01',\n",
       " 0.642,\n",
       " ' Precision: 0.679+/-0.01',\n",
       " 0.679,\n",
       " 'RECALL :0.609+/-0.61')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score(rf_gini, Train, y_Train, Train.columns,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112.96 , 4251.96\n",
      "533.24 , 722.24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.993+/-0.0',\n",
       " '0.81+/-0.0',\n",
       " '0.639+/-0.01',\n",
       " 0.639,\n",
       " ' Precision: 0.676+/-0.01',\n",
       " 0.676,\n",
       " 'RECALL :0.606+/-0.61')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score(rf_entropy, Train, y_Train, Train.columns,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf_entropy.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5594\n",
      "IsCanceled    6826\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(prediction.sum())\n",
    "\n",
    "print(y_Test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14161"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "for i,x in enumerate(y_Test.IsCanceled):\n",
    "    if prediction[i] == x:\n",
    "        a+=1\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy looks like the best choice although both criterias are very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest params\n",
    "param_grid = { \n",
    "    'max_depth' : range(5,16),\n",
    "    'min_impurity_decrease' : [0.01,0.03,0.05],\n",
    "    'min_samples_leaf': range(80,200,40),\n",
    "    'min_samples_split':range(200,1001,300)\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf_entropy, param_grid = param_grid, scoring = 'recall')\n",
    "\n",
    "grid_search.fit(Train, y_Train)\n",
    "grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(criterion='entropy', max_depth=13, min_impurity_decrease=0.01, min_samples_leaf=170, min_samples_split=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165.2 , 1119.48\n",
      "670.0 , 3665.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.731+/-0.01',\n",
       " '0.73+/-0.03',\n",
       " '0.566+/-0.01',\n",
       " 0.566,\n",
       " ' Precision: 0.523+/-0.07',\n",
       " 0.523,\n",
       " 'RECALL :0.635+/-0.63')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score(rf_model, Train, y_Train, Train.columns,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rf_model.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13289"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "for i,x in enumerate(y_Test.IsCanceled):\n",
    "    if y_test_pred[i] == x:\n",
    "        a+=1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c5bc60f1b709cc28d984b044e46a36e86d71fb0a6f2e3589923fa1d0135e80a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
